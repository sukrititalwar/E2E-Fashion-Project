{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-20T14:12:11.530321Z",
     "iopub.status.busy": "2025-07-20T14:12:11.530031Z",
     "iopub.status.idle": "2025-07-20T14:12:18.449713Z",
     "shell.execute_reply": "2025-07-20T14:12:18.448979Z",
     "shell.execute_reply.started": "2025-07-20T14:12:11.530302Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q streamlit pandas opencv-python-headless Pillow tensorflow \"scikit-learn>=1.0\" pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T14:12:18.451619Z",
     "iopub.status.busy": "2025-07-20T14:12:18.451415Z",
     "iopub.status.idle": "2025-07-20T14:12:18.463083Z",
     "shell.execute_reply": "2025-07-20T14:12:18.462128Z",
     "shell.execute_reply.started": "2025-07-20T14:12:18.451598Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import streamlit as st\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "# --- Page Configuration ---\n",
    "st.set_page_config(layout=\"wide\", page_title=\"AI Fashion Stylist\")\n",
    "\n",
    "# --- PATHS ---\n",
    "# IMPORTANT: Update these folder names to match your Kaggle datasets\n",
    "SAVED_OUTPUT_DIR = \"/kaggle/input/final-recommendation\" \n",
    "BASE_DATA_DIR = \"/kaggle/input/clothestry/clothes_tryon_dataset\"\n",
    "STYLE_CSV_PATH = \"/kaggle/input/description-and-style/cloth_style_profile.csv\" \n",
    "DESC_CSV_PATH = \"/kaggle/input/description-and-style/cloth_description_profile.csv\"\n",
    "FEATURES_PATH = \"/kaggle/input/embeddings/embeddings_full_dataset.pkl\"\n",
    "MAP_PATH = os.path.join(SAVED_OUTPUT_DIR, \"file_split_map.pkl\") if os.path.exists(SAVED_OUTPUT_DIR) else \"\" # Handle if map is missing\n",
    "UPLOAD_DIR = \"/kaggle/working/uploads\"\n",
    "\n",
    "if not os.path.exists(UPLOAD_DIR): os.makedirs(UPLOAD_DIR)\n",
    "\n",
    "# --- Caching Functions ---\n",
    "@st.cache_data\n",
    "def load_data_and_embeddings():\n",
    "    style_df = pd.read_csv(STYLE_CSV_PATH)\n",
    "    desc_df = pd.read_csv(DESC_CSV_PATH)\n",
    "    df = pd.merge(style_df, desc_df, on='filename', how='inner')\n",
    "    \n",
    "    with open(FEATURES_PATH, 'rb') as f: embeddings_list = pickle.load(f)\n",
    "    \n",
    "    # Re-create the file_map_df on the fly as a robust fallback\n",
    "    train_files = sorted([f for f in os.listdir(os.path.join(BASE_DATA_DIR, \"train/cloth\")) if f.endswith('.jpg')])\n",
    "    test_files = sorted([f for f in os.listdir(os.path.join(BASE_DATA_DIR, \"test/cloth\")) if f.endswith('.jpg')])\n",
    "    all_files_in_order = train_files + test_files\n",
    "    \n",
    "    file_map_df = pd.DataFrame({'filename': all_files_in_order, 'split': ['train'] * len(train_files) + ['test'] * len(test_files)})\n",
    "    \n",
    "    min_len = min(len(embeddings_list), len(file_map_df))\n",
    "    file_map_df = file_map_df.iloc[:min_len]\n",
    "    embeddings_list = embeddings_list[:min_len]\n",
    "\n",
    "    file_map_df['resnet_embedding'] = embeddings_list\n",
    "    final_df = pd.merge(df, file_map_df, on='filename', how='inner')\n",
    "    \n",
    "    final_df['cloth_path'] = final_df.apply(lambda r: os.path.join(BASE_DATA_DIR, r['split'], 'cloth', r['filename']), axis=1)\n",
    "    final_df['model_path'] = final_df.apply(lambda r: os.path.join(BASE_DATA_DIR, r['split'], 'image', r['filename']), axis=1)\n",
    "    final_df['search_text'] = (final_df['style_category'] + ' ' + final_df['description']).str.lower()\n",
    "    \n",
    "    # Get dominant color RGB for color harmony\n",
    "    final_df['rgb_values'] = final_df['dominant_color_rgb'].apply(lambda x: tuple(map(int, x.strip(\"()\").split(','))) if isinstance(x, str) else (0,0,0))\n",
    "\n",
    "    return final_df\n",
    "\n",
    "@st.cache_resource\n",
    "def get_recommendation_model(_df):\n",
    "    embeddings = np.array(_df['resnet_embedding'].tolist())\n",
    "    neighbors = NearestNeighbors(n_neighbors=6, algorithm='brute', metric='cosine').fit(embeddings)\n",
    "    return neighbors\n",
    "\n",
    "# --- NEW: Personalized Recommendation Logic ---\n",
    "\n",
    "@st.cache_resource\n",
    "def load_face_hair_cascade():\n",
    "    # Using pre-trained Haar Cascades for detection\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    return face_cascade\n",
    "\n",
    "def get_dominant_color(image, k=3):\n",
    "    image = image.reshape((image.shape[0] * image.shape[1], 3))\n",
    "    clt = KMeans(n_clusters=k, n_init='auto')\n",
    "    clt.fit(image)\n",
    "    # Return the most dominant color cluster center\n",
    "    return clt.cluster_centers_[np.argmax(np.unique(clt.labels_, return_counts=True)[1])]\n",
    "\n",
    "def analyze_facial_features(image_path, face_cascade):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    bgr_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # For display in Streamlit\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    if len(faces) == 0:\n",
    "        return None, None, None\n",
    "\n",
    "    # Use the largest detected face\n",
    "    (x, y, w, h) = sorted(faces, key=lambda f: f[2]*f[3], reverse=True)[0]\n",
    "    \n",
    "    \n",
    "    # Crop to the center of the face (cheeks/forehead) to avoid beards/lips\n",
    "    face_roi = img[y + int(h*0.2):y + int(h*0.6), x + int(w*0.2):x + int(w*0.8)]\n",
    "    dominant_skin_color = get_dominant_color(face_roi)\n",
    "\n",
    "    # Approximate hair region as the area above the face\n",
    "    hair_y_end = y + int(h*0.3)\n",
    "    hair_roi = img[max(0, y-int(h*0.4)):hair_y_end, x:x+w]\n",
    "    if hair_roi.shape[0] == 0 or hair_roi.shape[1] == 0:\n",
    "        dominant_hair_color = (0,0,0) # Default if no hair is found\n",
    "    else:\n",
    "        dominant_hair_color = get_dominant_color(hair_roi)\n",
    "    \n",
    "    # Draw rectangles for visualization\n",
    "    cv2.rectangle(bgr_img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    cv2.rectangle(bgr_img, (x, max(0, y-int(h*0.4))), (x+w, hair_y_end), (0, 255, 0), 2) # Hair region\n",
    "    \n",
    "    return dominant_skin_color, dominant_hair_color, bgr_img\n",
    "\n",
    "def classify_tone_and_color(rgb_skin, rgb_hair):\n",
    "    # Simplified classification based on brightness (Luminance)\n",
    "    skin_brightness = 0.299*rgb_skin[0] + 0.587*rgb_skin[1] + 0.114*rgb_skin[2]\n",
    "    if skin_brightness > 180: skin_tone = \"Light\"\n",
    "    elif skin_brightness > 110: skin_tone = \"Medium\"\n",
    "    else: skin_tone = \"Dark\"\n",
    "    \n",
    "    # Simplified classification for hair color\n",
    "    r, g, b = rgb_hair\n",
    "    if r > 100 and g > 100 and b < 100: hair_color = \"Blonde\"\n",
    "    elif r > 120 and g < 100 and b < 100: hair_color = \"Red\"\n",
    "    elif max(r,g,b) < 80: hair_color = \"Black\"\n",
    "    else: hair_color = \"Brown\"\n",
    "        \n",
    "    return skin_tone, hair_color\n",
    "\n",
    "def get_color_harmony_recommendations(skin_tone, hair_color, df, num_recs=10):\n",
    "    # --- Color Harmony Rules (This can be greatly expanded) ---\n",
    "    harmony_rules = {\n",
    "        \"Light\": [(10, 60, 100), (200, 150, 150)], # Blues, Pastels\n",
    "        \"Medium\": [(0, 100, 0), (128, 0, 128)], # Greens, Purples\n",
    "        \"Dark\": [(255, 0, 0), (0, 0, 255)], # Vibrant Reds, Blues\n",
    "    }\n",
    "    target_colors = harmony_rules.get(skin_tone, harmony_rules[\"Medium\"])\n",
    "    \n",
    "    all_cloth_colors = np.array(df['rgb_values'].tolist())\n",
    "    \n",
    "    # Find clothes closest to our target harmony colors\n",
    "    scores = []\n",
    "    for target_color in target_colors:\n",
    "        distances = np.sqrt(np.sum((all_cloth_colors - target_color)**2, axis=1))\n",
    "        scores.append(distances)\n",
    "        \n",
    "    # Average the distances and find the indices with the smallest average distance\n",
    "    avg_scores = np.mean(scores, axis=0)\n",
    "    recommended_indices = np.argsort(avg_scores)[:num_recs]\n",
    "    \n",
    "    return df.iloc[recommended_indices]\n",
    "\n",
    "\n",
    "# Load data and models\n",
    "df = load_data_and_embeddings()\n",
    "resnet_neighbors = get_recommendation_model(df)\n",
    "face_cascade = load_face_hair_cascade()\n",
    "\n",
    "st.title(\"👗 AI Personal Fashion Stylist\")\n",
    "\n",
    "# Create tabs for different functionalities\n",
    "tab1, tab2 = st.tabs([\"Personalized Recommendations\", \"Catalog & Visual Search\"])\n",
    "\n",
    "with tab1:\n",
    "    st.header(\"Upload Your Photo for Personalized Styling\")\n",
    "    st.write(\"Our AI will analyze your skin tone and hair color to recommend outfits that complement your features.\")\n",
    "    \n",
    "    uploaded_file = st.file_uploader(\"Choose your image...\", type=['jpg', 'jpeg', 'png'], key=\"persona_upload\")\n",
    "    \n",
    "    if uploaded_file:\n",
    "        file_path = os.path.join(UPLOAD_DIR, uploaded_file.name)\n",
    "        with open(file_path, \"wb\") as f: f.write(uploaded_file.getbuffer())\n",
    "        \n",
    "        with st.spinner(\"Analyzing your features...\"):\n",
    "            skin_rgb, hair_rgb, annotated_img = analyze_facial_features(file_path, face_cascade)\n",
    "        \n",
    "        if skin_rgb is not None:\n",
    "            skin_tone, hair_color = classify_tone_and_color(skin_rgb, hair_rgb)\n",
    "            \n",
    "            col1, col2 = st.columns(2)\n",
    "            with col1:\n",
    "                st.image(annotated_img, channels=\"BGR\", caption=\"AI Analysis (Face in Blue, Hair in Green)\")\n",
    "            with col2:\n",
    "                st.subheader(\"Your AI Style Profile:\")\n",
    "                st.write(f\"**Detected Skin Tone:** {skin_tone}\")\n",
    "                st.write(f\"**Detected Hair Color:** {hair_color}\")\n",
    "                st.color_picker(\"Dominant Skin Tone\", value=f\"#{int(skin_rgb[0]):02x}{int(skin_rgb[1]):02x}{int(skin_rgb[2]):02x}\")\n",
    "                st.color_picker(\"Dominant Hair Color\", value=f\"#{int(hair_rgb[0]):02x}{int(hair_rgb[1]):02x}{int(hair_rgb[2]):02x}\")\n",
    "\n",
    "            st.markdown(\"---\")\n",
    "            st.subheader(f\"🎨 Recommended Colors for You\")\n",
    "            \n",
    "            rec_df = get_color_harmony_recommendations(skin_tone, hair_color, df)\n",
    "            st.image([c for c in rec_df['cloth_path']], width=120, caption=[s for s in rec_df['style_category']])\n",
    "            \n",
    "        else:\n",
    "            st.error(\"Could not detect a face in the uploaded image. Please try a clearer, front-facing photo.\")\n",
    "\n",
    "with tab2:\n",
    "    # This is your previous app logic, now neatly in a tab\n",
    "    st.header(\"Catalog Search & Visual Recommendations\")\n",
    "    if 'view' not in st.session_state: st.session_state.view = 'catalog'\n",
    "    if 'selected_item_idx' not in st.session_state: st.session_state.selected_item_idx = None\n",
    "    \n",
    "    if st.session_state.view == 'detail':\n",
    "        item = df.iloc[st.session_state.selected_item_idx]\n",
    "        if st.button(\"⬅️ Back to Catalog\", key=\"back_btn\"): st.session_state.view = 'catalog'; st.rerun()\n",
    "        # Detail view layout here...\n",
    "        st.header(f\"Details for {item['style_category']}\")\n",
    "        col1, col2 = st.columns(2)\n",
    "        with col1: st.image(item['model_path'], caption=\"Model View\", use_container_width=True)\n",
    "        with col2: st.image(item['cloth_path'], caption=\"Garment View\", use_container_width=True)\n",
    "        st.subheader(f\"**AI Description:** *{item['description']}*\")\n",
    "        st.markdown(\"---\"); st.header(\"✨ Visually Similar Items (ResNet)\")\n",
    "        item_embedding = item['resnet_embedding'].reshape(1, -1)\n",
    "        _, indices = resnet_neighbors.kneighbors(item_embedding)\n",
    "        rec_df = df.iloc[indices[0][1:]]\n",
    "        st.image([c for c in rec_df['cloth_path']], width=120, caption=[s for s in rec_df['style_category']])\n",
    "    else:\n",
    "        # Catalog view layout here...\n",
    "        st.sidebar.header(\"🔍 Search & Filter\")\n",
    "        search_query = st.sidebar.text_input(\"Search by description\")\n",
    "        style_options = ['All'] + sorted(df['style_category'].unique().tolist())\n",
    "        sel_style = st.sidebar.selectbox(\"Filter by Style Category:\", style_options)\n",
    "        \n",
    "        filtered_df = df.copy()\n",
    "        if search_query:\n",
    "            for term in search_query.lower().split(): filtered_df = filtered_df[filtered_df['search_text'].str.contains(term, na=False)]\n",
    "        if sel_style != 'All': filtered_df = filtered_df[filtered_df['style_category'] == sel_style]\n",
    "\n",
    "        st.header(f\"Browse Our Collection ({len(filtered_df)} items found)\")\n",
    "        items_per_page = 20; page_num = st.sidebar.number_input(f'Page', 1, max(1, (len(filtered_df)-1)//items_per_page+1), 1)\n",
    "        start, end = (page_num - 1) * items_per_page, page_num * items_per_page\n",
    "        paginated_df = filtered_df.iloc[start:end]\n",
    "        \n",
    "        cols = st.columns(5)\n",
    "        for i, (idx, row) in enumerate(paginated_df.iterrows()):\n",
    "            with cols[i % 5]:\n",
    "                st.image(row['cloth_path'], use_container_width=True)\n",
    "                st.caption(row['style_category'])\n",
    "                if st.button(\"View Details\", key=f\"view_{idx}\"):\n",
    "                    st.session_state.selected_item_idx = idx; st.session_state.view = 'detail'; st.rerun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T14:12:18.464410Z",
     "iopub.status.busy": "2025-07-20T14:12:18.463887Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ngrok: no process found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================                                   \n",
      "🎉 Your Streamlit App is LIVE! Click the link below to open it: 🎉\n",
      "NgrokTunnel: \"https://f5f0c6a4bdd2.ngrok-free.app\" -> \"http://localhost:8501\"\n",
      "=================================================================\n",
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.19.2.2:8501\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.90.130.73:8501\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "from pyngrok import ngrok\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Get your ngrok token from secrets\n",
    "user_secrets = UserSecretsClient()\n",
    "NGROK_AUTH_TOKEN = user_secrets.get_secret(\"NGROK_AUTH_TOKEN\")\n",
    "\n",
    "# Authenticate and create tunnel\n",
    "os.system(\"killall ngrok\")\n",
    "time.sleep(2)\n",
    "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "public_url = ngrok.connect(8501)\n",
    "\n",
    "# Print the public URL for you to click\n",
    "print(\"=\"*65)\n",
    "print(f\" Your Streamlit App is LIVE! Click the link below to open it: 🎉\")\n",
    "print(public_url)\n",
    "print(\"=\"*65)\n",
    "\n",
    "# Run the Streamlit app\n",
    "!streamlit run app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
