{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12488443,"sourceType":"datasetVersion","datasetId":7880652},{"sourceId":12521699,"sourceType":"datasetVersion","datasetId":7903971},{"sourceId":12521709,"sourceType":"datasetVersion","datasetId":7903978},{"sourceId":12525287,"sourceType":"datasetVersion","datasetId":7906515},{"sourceId":12527138,"sourceType":"datasetVersion","datasetId":7907814}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Install Dependencies\n# Run this cell first to install all the required Python packages.\n# This might take a minute or two to complete.\n\nprint(\"--- Installing required libraries... ---\")\n!pip install -q streamlit pyngrok scikit-learn tensorflow opencv-python\nprint(\"✅ Libraries installed successfully!\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-20T18:14:17.596898Z","iopub.execute_input":"2025-07-20T18:14:17.597625Z","iopub.status.idle":"2025-07-20T18:14:21.123518Z","shell.execute_reply.started":"2025-07-20T18:14:17.597599Z","shell.execute_reply":"2025-07-20T18:14:21.122544Z"}},"outputs":[{"name":"stdout","text":"--- Installing required libraries... ---\n✅ Libraries installed successfully!\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"%%writefile app.py\nimport streamlit as st\nimport os\nimport pandas as pd\nimport numpy as np\nimport pickle\nfrom PIL import Image\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.cluster import KMeans\nimport random\nimport cv2\nimport requests\nfrom numpy.linalg import norm\nfrom collections import Counter\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\nfrom tensorflow.keras.layers import GlobalMaxPooling2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing import image\n\n# --- 1. PAGE AND SESSION STATE CONFIGURATION ---\nst.set_page_config(layout=\"wide\", page_title=\"AI Fashion Finder\")\n\n# Initialize session state variables\nif 'view' not in st.session_state: st.session_state.view = 'catalog'\nif 'selected_item_idx' not in st.session_state: st.session_state.selected_item_idx = None\nif 'history' not in st.session_state: st.session_state.history = []\nif 'cart' not in st.session_state: st.session_state.cart = []\nif 'weekly_planner' not in st.session_state:\n    st.session_state.weekly_planner = {day: [] for day in [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]}\nif 'style_profile' not in st.session_state:\n    st.session_state.style_profile = {'likes': [], 'dislikes': [], 'recommendations': pd.DataFrame()}\nif 'quiz_complete' not in st.session_state:\n    st.session_state.quiz_complete = False\n\n\n# --- 2. DATA AND MODEL LOADING (UNCHANGED) ---\n@st.cache_resource\ndef download_haar_cascade():\n    HAAR_CASCADE_PATH = \"haarcascade_frontalface_default.xml\"\n    if not os.path.exists(HAAR_CASCADE_PATH):\n        CASCADE_URL = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\"\n        try:\n            r = requests.get(CASCADE_URL); r.raise_for_status()\n            with open(HAAR_CASCADE_PATH, 'wb') as f: f.write(r.content)\n            return HAAR_CASCADE_PATH\n        except: return None\n    return HAAR_CASCADE_PATH\n\n@st.cache_resource\ndef load_feature_extraction_model():\n    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n    base_model.trainable = False\n    model = Sequential([base_model, GlobalMaxPooling2D()])\n    return model\n\nBASE_DATA_DIR = \"/kaggle/input/clothestry/clothes_tryon_dataset\"\nSTYLE_CSV_PATH = \"/kaggle/input/cloth-style-profile/cloth_style_profile.csv\"\nDESC_CSV_PATH = \"/kaggle/input/cloth-description-profile/cloth_description_profile.csv\"\nFEATURES_PATH = \"/kaggle/input/embeddings/embeddings_full_dataset.pkl\"\nMAP_PATH = \"/kaggle/input/splitmap/file_split_map.pkl\"\nUPLOAD_DIR = \"uploads\"\nif not os.path.exists(UPLOAD_DIR): os.makedirs(UPLOAD_DIR)\nHAAR_CASCADE_PATH = download_haar_cascade()\nDAYS_OF_WEEK = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n\n@st.cache_data\ndef load_data():\n    for path in [STYLE_CSV_PATH, DESC_CSV_PATH, FEATURES_PATH, MAP_PATH]:\n        if not os.path.exists(path): return pd.DataFrame()\n    try:\n        style_df = pd.read_csv(STYLE_CSV_PATH)\n        desc_df = pd.read_csv(DESC_CSV_PATH)\n        df = pd.merge(style_df, desc_df, on='filename', how='inner')\n        with open(FEATURES_PATH, 'rb') as f: embeddings = list(pickle.load(f))\n        file_map_df = pd.read_pickle(MAP_PATH)\n        if len(embeddings) != len(file_map_df): return pd.DataFrame()\n        file_map_df['resnet_embedding'] = embeddings\n        final_df = pd.merge(df, file_map_df, on='filename', how='inner').reset_index(drop=True)\n        final_df['cloth_path'] = final_df.apply(lambda r: os.path.join(BASE_DATA_DIR, r['split'], 'cloth', r['filename']), axis=1)\n        final_df['model_path'] = final_df.apply(lambda r: os.path.join(BASE_DATA_DIR, r['split'], 'image', r['filename']), axis=1)\n        final_df['search_text'] = (final_df['style_category'] + ' ' + final_df['description']).str.lower()\n        return final_df\n    except: return pd.DataFrame()\n\n@st.cache_resource\ndef get_nn_model(_df):\n    if _df.empty: return None\n    return NearestNeighbors(n_neighbors=21, algorithm='brute', metric='cosine').fit(np.array(_df['resnet_embedding'].tolist()))\n\n@st.cache_resource\ndef load_face_detector():\n    if not HAAR_CASCADE_PATH: return None\n    return cv2.CascadeClassifier(HAAR_CASCADE_PATH)\n\n\n# --- 3. CORE FUNCTIONALITY (WITH NEW QUIZ RECOMMENDATION LOGIC) ---\ndef extract_features_from_image(image_path, model):\n    img = image.load_img(image_path, target_size=(224, 224)); img_array = image.img_to_array(img)\n    expanded_img_array = np.expand_dims(img_array, axis=0)\n    preprocessed_img = preprocess_input(expanded_img_array)\n    result = model.predict(preprocessed_img).flatten()\n    return result / norm(result)\n\ndef get_recommendations_by_vector(vector, nn_model, num_recs=20):\n    distances, indices = nn_model.kneighbors([vector])\n    return indices[0][:num_recs]\n\ndef display_interactive_results(results_df):\n    if results_df.empty:\n        st.info(\"No items match your specific criteria. Try broadening your search!\")\n        return\n    cols = st.columns(5)\n    for i, (idx, row) in enumerate(results_df.iterrows()):\n        with cols[i % 5]:\n            st.image(row['cloth_path'], use_container_width=True)\n            st.caption(row['filename'])\n            c1, c2 = st.columns(2)\n            with c1:\n                if st.button(\"🛒\", key=f\"rec_cart_{idx}\", help=\"Add to Cart\"):\n                    if idx not in st.session_state.cart: st.session_state.cart.append(idx); st.success(\"Added!\")\n                    else: st.info(\"In cart\")\n            with c2:\n                if st.button(\"👁️\", key=f\"rec_view_{idx}\", help=\"View Details\"):\n                    st.session_state.selected_item_idx = idx; st.session_state.view = 'detail'; st.info(\"Go to 'Catalog' tab.\")\n                    st.rerun()\n\n# ==========================================================\n#  NEW: Smart Quiz Recommendation Engine\n# ==========================================================\ndef get_recommendations_from_quiz(df, likes, dislikes, min_results=5):\n    \"\"\"\n    Generates recommendations based on a list of liked and disliked keywords.\n    \"\"\"\n    filtered_df = df.copy()\n\n    # Negative filtering: remove all items that contain disliked keywords\n    if dislikes:\n        dislike_query = '|'.join(dislikes)\n        filtered_df = filtered_df[~filtered_df['search_text'].str.contains(dislike_query, na=False)]\n\n    # Positive filtering: find items that match liked keywords\n    if likes:\n        # Score items based on how many 'like' keywords they match\n        filtered_df['score'] = filtered_df['search_text'].apply(lambda text: sum(1 for keyword in likes if keyword in text))\n        \n        # Prioritize items with more matches\n        results = filtered_df[filtered_df['score'] > 0].sort_values(by='score', ascending=False)\n    else:\n        # If no likes, just use the dislike-filtered list\n        results = filtered_df\n\n    # Fallback: If results are too few, relax the criteria\n    if len(results) < min_results:\n        # If there were likes, try matching ANY liked term instead of scoring\n        if likes:\n            like_query = '|'.join(likes)\n            results = filtered_df[filtered_df['search_text'].str.contains(like_query, na=False)]\n    \n    # Final Fallback: if still not enough, just show the most popular items from the dislike-filtered list\n    if len(results) < min_results:\n        results = filtered_df.head(min_results)\n\n    return results.head(20) # Return up to 20 top results\n\n# --- Other Core Functions (unchanged) ---\n# ... (omitted for brevity)\n\n# --- 4. LOAD DATA AND MODELS ---\ndf = load_data()\nif df.empty: st.error(\"Application cannot start due to data loading issues.\"); st.stop()\nresnet_neighbors = get_nn_model(df)\nface_detector = load_face_detector()\nfeature_extractor = load_feature_extraction_model()\n\n# --- 5. SIDEBAR NAVIGATION ---\nst.sidebar.title(\"MENU\"); cart_count = len(st.session_state.cart)\nmain_tab = st.sidebar.radio(\"Navigate\", [\"🏠 Home\", \"🛍️ Catalog & Search\", \"✨ My Style Profile\", \"🗓️ Weekly Planner\", f\"🛒 Cart ({cart_count})\"])\n\n\n# --- 6. UI: MAIN PAGE RENDERING ---\nif main_tab == \"🏠 Home\":\n    st.markdown('<h1>👗 AI Fashion Finder</h1>', unsafe_allow_html=True); st.markdown('<p>Welcome! Your smart fashion assistant is here. Use the menu on the left to explore our collection, get personalized style recommendations, plan your weekly outfits, and manage your shopping cart.</p>', unsafe_allow_html=True)\n    st.image(\"https://images.unsplash.com/photo-1441986300917-64674bd600d8?q=80&w=2070&auto=format&fit=crop\", use_container_width=True)\n\n# ==========================================================\n#  NEW: DEEP STYLE QUIZ IMPLEMENTATION\n# ==========================================================\nelif main_tab == \"✨ My Style Profile\":\n    st.header(\"✨ Create Your AI-Powered Style Profile\")\n    \n    quiz_tab, recs_tab, analysis_tab = st.tabs([\"**Deep Style Quiz**\", \"**Your Recommendations**\", \"**Visual Search & Complexion**\"])\n\n    with quiz_tab:\n        st.subheader(\"Help our AI understand your unique taste.\")\n        st.write(\"The more you tell us, the better your recommendations will be!\")\n\n        with st.form(\"deep_quiz_form\"):\n            st.markdown(\"#### Part 1: Your Go-To Styles\")\n            occasions = st.multiselect(\n                \"What occasions do you usually dress for? (Select all that apply)\",\n                ['Casual Day Out', 'Office & Work', 'Workout & Gym', 'Party & Evening', 'Formal Event', 'Vacation'],\n                key='occasions'\n            )\n\n            st.markdown(\"#### Part 2: Colors & Patterns\")\n            colors = st.multiselect(\n                \"Which color palettes are you drawn to?\",\n                ['Neutral (black, white, beige)', 'Pastels (light pink, baby blue)', 'Earthy (brown, green, rust)', 'Jewel Tones (emerald, ruby, sapphire)', 'Bright & Bold (neon, primary colors)'],\n                key='colors'\n            )\n            \n            patterns = st.multiselect(\n                \"What about prints and patterns?\",\n                ['Solid Colors (No pattern)', 'Floral', 'Stripes', 'Polka Dots', 'Animal Print (leopard, snake)', 'Geometric'],\n                key='patterns'\n            )\n\n            st.markdown(\"#### Part 3: What to Avoid\")\n            dislikes = st.multiselect(\n                \"Are there any styles or patterns you actively dislike?\",\n                ['Floral', 'Stripes', 'Polka Dots', 'Animal Print', 'Neon Colors', 'Oversized Fit', 'Tight Fit'],\n                key='dislikes'\n            )\n            \n            submitted = st.form_submit_button(\"Generate My Style Profile!\", type=\"primary\")\n\n            if submitted:\n                # --- Map quiz answers to keywords ---\n                like_keywords = []\n                # Map occasions and styles\n                occasion_map = {'Casual Day Out': ['casual', 't-shirt', 'jeans'], 'Office & Work': ['blouse', 'trousers', 'formal'], 'Workout & Gym': ['activewear', 'sporty'], 'Party & Evening': ['dress', 'elegant', 'sequin']}\n                for o in occasions: like_keywords.extend(occasion_map.get(o, []))\n                \n                # Map colors\n                color_map = {'Neutral': ['black', 'white', 'beige', 'gray'], 'Pastels': ['pink', 'blue', 'lavender'], 'Earthy': ['green', 'brown', 'tan'], 'Jewel Tones': ['red', 'emerald', 'blue'], 'Bright & Bold': ['yellow', 'orange', 'neon']}\n                for c in colors: like_keywords.extend(color_map.get(c, []))\n\n                # Map patterns\n                pattern_map = {'Solid Colors': ['solid', 'plain'], 'Floral': ['floral'], 'Stripes': ['stripe'], 'Polka Dots': ['dot'], 'Animal Print': ['leopard', 'zebra', 'snake'], 'Geometric': ['geometric', 'abstract']}\n                for p in patterns: like_keywords.extend(pattern_map.get(p, []))\n                \n                # --- Map dislikes ---\n                dislike_keywords = []\n                dislike_map = {'Floral': ['floral'], 'Stripes': ['stripe'], 'Animal Print': ['leopard', 'zebra', 'snake'], 'Neon Colors': ['neon']}\n                for d in dislikes: dislike_keywords.extend(dislike_map.get(d, []))\n                \n                st.session_state.style_profile['likes'] = list(set(like_keywords))\n                st.session_state.style_profile['dislikes'] = list(set(dislike_keywords))\n                \n                recs = get_recommendations_from_quiz(df, st.session_state.style_profile['likes'], st.session_state.style_profile['dislikes'])\n                st.session_state.style_profile['recommendations'] = recs\n                st.session_state.quiz_complete = True\n                st.success(\"Your profile has been created! Head over to the 'Your Recommendations' tab to see what we found for you.\")\n    \n    with recs_tab:\n        if not st.session_state.quiz_complete:\n            st.info(\"⬅️ Please complete the Deep Style Quiz first to see your personalized recommendations.\")\n        else:\n            st.subheader(\"✨ Here are some items we think you'll love\")\n            st.write(f\"Based on your preferences for: **{', '.join(st.session_state.style_profile['likes'])}**\")\n            st.write(f\"And avoiding: **{', '.join(st.session_state.style_profile['dislikes'])}**\")\n            st.markdown(\"---\")\n            \n            recs_df = st.session_state.style_profile['recommendations']\n            display_interactive_results(recs_df)\n\n    with analysis_tab:\n        # Visual Search and Complexion Analysis code remains the same\n        st.subheader(\"Find it! Got a photo of clothing you love?\")\n        st.write(\"Upload an image of a garment, and our AI will find similar items in our catalog.\")\n        item_uploader = st.file_uploader(\"Upload clothing photo\", type=['jpg','png','jpeg'], key=\"item_uploader\")\n        if item_uploader:\n            fp = os.path.join(UPLOAD_DIR, item_uploader.name)\n            with open(fp, \"wb\") as f: f.write(item_uploader.getbuffer())\n            c1, c2 = st.columns([1, 2])\n            with c1: st.image(fp, caption=\"Your Uploaded Image\", use_container_width=True)\n            with c2:\n                with st.spinner(\"Analyzing style, color, and pattern...\"):\n                    uploaded_features = extract_features_from_image(fp, feature_extractor)\n                    rec_indices = get_recommendations_by_vector(uploaded_features, resnet_neighbors, 20)\n                    st.success(f\"Found {len(rec_indices)} similar items!\")\n            st.markdown(\"---\"); st.header(\"Here's what we found:\")\n            display_interactive_results(df.iloc[rec_indices])\n            \n        st.markdown(\"---\")\n        st.subheader(\"Get recommendations based on your unique coloring.\")\n        # ... (complexion analysis code is unchanged)\n\n# --- Other Pages (Planner, Cart, Catalog) ---\n# ... The code for these pages is the same as the last full version.\n# I've pasted it here for completeness.\nelif main_tab == \"🗓️ Weekly Planner\":\n    st.header(\"🗓️ Your Weekly Outfit Planner\"); st.info(\"Plan your outfits! Add items from the catalog's detail page.\")\n    if st.button(\"Clear Entire Plan\", key=\"clear_plan\"): st.session_state.weekly_planner = {d:[] for d in DAYS_OF_WEEK}; st.rerun()\n    for day in DAYS_OF_WEEK:\n        with st.expander(f\"**{day}** ({len(st.session_state.weekly_planner[day])} items)\"):\n            if st.session_state.weekly_planner[day]:\n                cols = st.columns(5)\n                for i, idx in enumerate(st.session_state.weekly_planner[day]):\n                    with cols[i % 5]:\n                        st.image(df.loc[idx]['cloth_path'], use_container_width=True)\n                        if st.button(\"❌\", key=f\"rem_plan_{day}_{idx}\", help=\"Remove\"): st.session_state.weekly_planner[day].remove(idx); st.rerun()\n            else: st.caption(\"No outfit planned for this day.\")\n\nelif main_tab.startswith(\"🛒 Cart\"):\n    st.header(f\"🛒 Shopping Cart ({cart_count} items)\");\n    if not st.session_state.cart: st.info(\"Your cart is empty. Add items from the catalog!\")\n    else:\n        for i, idx in enumerate(st.session_state.cart):\n            item = df.loc[idx]; col1, col2, col3 = st.columns([1, 4, 1])\n            with col1: st.image(item['cloth_path'], width=100)\n            with col2: st.subheader(f\"{item['style_category']}\"); st.caption(f\"Item ID: {idx}\")\n            with col3:\n                if st.button(\"Remove\", key=f\"rem_cart_{idx}\"): st.session_state.cart.remove(idx); st.rerun()\n            st.markdown(\"---\")\n        if st.button(\"Request All Items\", type=\"primary\", use_container_width=True): st.success(\"Demo: Your request would be sent to the store!\"); st.balloons()\n\nelse: # Catalog & Search Tab\n    if st.session_state.view == 'detail':\n        idx = st.session_state.selected_item_idx; item = df.loc[idx]\n        if st.button(\"⬅️ Back to Collection\"): st.session_state.view = 'catalog'; st.rerun()\n        c1, c2 = st.columns([1, 2])\n        with c1: st.image(item['model_path'], use_container_width=True, caption=\"Model View\")\n        with c2:\n            st.image(item['cloth_path'], use_container_width=True, caption=\"Garment View\")\n            st.header(item['style_category']); st.write(f\"**AI Description:** *{item['description']}*\")\n            st.markdown(\"---\")\n            if st.button(\"Add to Cart\", type=\"primary\"):\n                if idx not in st.session_state.cart: st.session_state.cart.append(idx); st.success(\"Added!\"); st.rerun()\n                else: st.info(\"Already in cart.\")\n            day_to_add = st.selectbox(\"Add to Planner:\", [\"- Select a Day -\"] + DAYS_OF_WEEK, key=f\"planner_add_{idx}\")\n            if day_to_add != \"- Select a Day -\":\n                if idx not in st.session_state.weekly_planner[day_to_add]:\n                    st.session_state.weekly_planner[day_to_add].append(idx); st.success(f\"Added to {day_to_add}!\")\n                else: st.info(f\"Already in {day_to_add}'s plan.\")\n        st.markdown(\"---\"); st.header(\"✨ Visually Similar Items\")\n        if resnet_neighbors:\n            distances, indices = resnet_neighbors.kneighbors(item['resnet_embedding'].reshape(1, -1))\n            cols = st.columns(5)\n            for i, rec_idx in enumerate(indices[0][1:6]):\n                with cols[i]:\n                    st.image(df.loc[rec_idx]['cloth_path'], caption=df.loc[rec_idx]['style_category'], use_container_width=True)\n    else: # Catalog View\n        st.markdown('<h1>🛍️ Catalog & Search</h1>', unsafe_allow_html=True)\n        with st.expander(\"🔍 Search & Filter\", expanded=True):\n            col1, col2 = st.columns([2, 1])\n            with col1: search_query = st.text_input(\"Search by description\")\n            with col2:\n                style_options = ['All'] + sorted(df['style_category'].unique().tolist())\n                selected_style = st.selectbox(\"Filter by Style Category:\", style_options)\n        filtered_df = df.copy()\n        if selected_style != 'All': filtered_df = filtered_df[filtered_df['style_category'] == selected_style]\n        if search_query: filtered_df = filtered_df[filtered_df['search_text'].str.contains(search_query.lower(), na=False)]\n        st.header(f\"Browse Our Collection ({len(filtered_df)} items found)\")\n        items_per_page = 15; total_pages = max(1, (len(filtered_df) - 1) // items_per_page + 1)\n        page_num = st.number_input('Page', min_value=1, max_value=total_pages, value=1)\n        start_idx = (page_num - 1) * items_per_page\n        end_idx = page_num * items_per_page\n        cols = st.columns(5)\n        for i, (idx, row) in enumerate(filtered_df.iloc[start_idx:end_idx].iterrows()):\n            with cols[i % 5]:\n                st.image(row['cloth_path'], use_container_width=True)\n                st.caption(f\"{row['style_category']}\")\n                if st.button(\"View Details\", key=f\"view_{idx}\"):\n                    st.session_state.selected_item_idx = idx; st.session_state.view = 'detail'\n                    if idx not in st.session_state.history: st.session_state.history.insert(0, idx)\n                    st.session_state.history = st.session_state.history[:5]; st.rerun()\n\n# --- SIDEBAR HISTORY ---\nst.sidebar.markdown(\"---\"); st.sidebar.header(\"🕰️ Recently Viewed\")\nif not st.session_state.history: st.sidebar.caption(\"No items viewed yet.\")\nelse:\n    for item_idx in st.session_state.history:\n        item = df.loc[item_idx]\n        if st.sidebar.button(f\"{item['style_category']} (View)\", key=f\"history_{item_idx}\", use_container_width=True):\n            st.session_state.selected_item_idx = item_idx; st.session_state.view = 'detail'\n            st.rerun()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T18:45:29.750534Z","iopub.execute_input":"2025-07-20T18:45:29.751107Z","iopub.status.idle":"2025-07-20T18:45:29.765230Z","shell.execute_reply.started":"2025-07-20T18:45:29.751081Z","shell.execute_reply":"2025-07-20T18:45:29.764364Z"}},"outputs":[{"name":"stdout","text":"Overwriting app.py\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"import os\nfrom pyngrok import ngrok\nfrom kaggle_secrets import UserSecretsClient # Import the Kaggle secrets client\n\n# --- IMPORTANT: Access the Ngrok token from Kaggle Secrets ---\n# This is the correct way to use secrets in a Kaggle environment.\ntry:\n    user_secrets = UserSecretsClient()\n    NGROK_AUTH_TOKEN = user_secrets.get_secret(\"NGROK_AUTH_TOKEN\")\n    print(\"✅ Successfully loaded NGROK_AUTH_TOKEN from Kaggle Secrets.\")\nexcept:\n    # This is a fallback in case the code is run outside Kaggle or the secret is missing\n    NGROK_AUTH_TOKEN = \"YOUR_NGROK_AUTHTOKEN_IS_MISSING\"\n# -----------------\n\n\n# Now, the rest of your code can proceed\nif \"MISSING\" in NGROK_AUTH_TOKEN:\n    print(\"\\n🛑 ERROR: Could not find Kaggle Secret 'NGROK_AUTH_TOKEN'.\")\n    print(\"   Please ensure you have added your Ngrok token as a secret on the right-hand panel and attached it to this notebook.\")\nelse:\n    # Set the auth token for pyngrok\n    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n\n    # Check if app.py exists before trying to run it\n    if not os.path.exists(\"app.py\"):\n        print(\"\\n🛑 ERROR: 'app.py' not found. Please make sure you have successfully run the previous cell to create it.\")\n    else:\n        try:\n            # Start the streamlit app and connect it to a public URL\n            public_url = ngrok.connect(8501)\n            print(\"--- Launching the Streamlit application... ---\")\n            print(\"🎉 Your app is live!\")\n            print(f\"🔗 Public URL: {public_url}\")\n            print(\"   (Note: The first time you open the app, it might take a moment to load.)\")\n\n            # This command runs the streamlit server. It will keep this cell running.\n            !streamlit run app.py --server.port 8501 --server.headless true\n\n        except Exception as e:\n            print(f\"\\n🛑 An error occurred with ngrok or Streamlit: {e}\")\n            print(\"   Please double-check that your NGROK_AUTH_TOKEN secret is correct and that you have internet connectivity.\")\n            # Kill any existing ngrok tunnels if an error occurs\n            ngrok.kill()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T18:45:33.936194Z","iopub.execute_input":"2025-07-20T18:45:33.936837Z","execution_failed":"2025-07-20T18:53:16.699Z"}},"outputs":[{"name":"stdout","text":"✅ Successfully loaded NGROK_AUTH_TOKEN from Kaggle Secrets.\n--- Launching the Streamlit application... ---\n🎉 Your app is live!\n🔗 Public URL: NgrokTunnel: \"https://4e851e194826.ngrok-free.app\" -> \"http://localhost:8501\"\n   (Note: The first time you open the app, it might take a moment to load.)\n\nCollecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n\u001b[0m\n\u001b[0m\n\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n\u001b[0m\n\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.19.2.2:8501\u001b[0m\n\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.9.102.104:8501\u001b[0m\n\u001b[0m\n2025-07-20 18:45:45.885649: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753037145.915184     757 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753037145.924043     757 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nI0000 00:00:1753037150.501670     757 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13586 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1753037150.502363     757 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13842 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1753037268.434030     787 service.cc:148] XLA service 0x78d6340024f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1753037268.434077     787 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1753037268.434082     787 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1753037269.020976     787 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1753037271.122618     787 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step\n","output_type":"stream"}],"execution_count":null}]}